# Seren â€” Plugah Orchestrator âœ¨

Seren is a minimal, runnable orchestrator around **[Plugah](https://github.com/cheesejaguar/plugah)** that drives dynamic agentic graph generation endâ€‘toâ€‘end:

1) ğŸ” Discovery â†’ 2) ğŸ“ PRD â†’ 3) ğŸ§© Organization Planning (OAG) â†’ 4) ğŸš€ Execution

It ships with a CLI and a small FastAPI service. Offline â€œmockâ€ mode is supported for CI and demos. ğŸ§ª

## Requirements

- Python 3.11+

## Install ğŸ“¦

```bash
# Editable install (recommended for development)
pip install -e ".[dev]"

# If Plugah isnâ€™t available from PyPI in your environment, you can install from GitHub:
# pip install "git+https://github.com/cheesejaguar/plugah.git"
```

## Quickstart (CLI) âš¡ï¸

Run the full pipeline nonâ€‘interactively in offline mock mode:

```bash
plugah-orchestrate quickstart \
  --problem "Build a Slack summarizer bot" \
  --budget 100 \
  --policy BALANCED \
  --model gpt-4o \
  --mock
```

Stageâ€‘byâ€‘stage:

```bash
# 1) Discovery â†’ questions.json
plugah-orchestrate init --problem "Build X" --budget 100 --policy BALANCED --model gpt-4o --mock

# Provide answers (edit answers.json or generate your own)
echo '["Answer 1","Answer 2"]' > answers.json

# 2) PRD â†’ prd.json, 3) OAG â†’ oag.json
plugah-orchestrate plan --answers-file answers.json --policy AGGRESSIVE --mock

# 4) Execution â†’ results.json (includes total_cost)
plugah-orchestrate run --mock
```

Generated artifacts in the repo root ğŸ“:

- questions.json
- answers.json (if you used quickstart auto generation)
- prd.json
- oag.json
- results.json

## Web API ğŸŒ

Start the API server:

```bash
plugah-web
# or: uvicorn app.web:app --host 127.0.0.1 --port 8000 --reload
```

Endpoints:

- POST /orchestrate

```json
{
  "problem": "Build a Slack summarizer bot",
  "budget": 100,
  "policy": "BALANCED",
  "model_hint": "gpt-4o",
  "mock": true
}
```

- POST /plan

```json
{
  "problem": "Build a Slack summarizer bot",
  "budget": 100,
  "answers": ["Answer 1", "Answer 2"],
  "policy": "BALANCED",
  "model_hint": "gpt-4o",
  "mock": true
}
```

- POST /execute â†’ returns execution result with `total_cost`.

## How it integrates with Plugah ğŸ”Œ

Seren now provides a planner used by [Plugah](https://github.com/cheesejaguar/plugah) during the Organization Planning phase. We inject `SerenPlanner` as Plugahâ€™s `Planner`, so when `BoardRoom.plan_organization()` runs, it calls into Seren.

Pipeline entrypoints remain:

- `startup_phase(problem, budget_usd, model_hint?, policy?)` â†’ questions
- `process_discovery(answers, problem, budget_usd, model_hint?, policy?)` â†’ PRD
- `plan_organization(prd, budget_usd, model_hint?, policy?)` â†’ OAG
- `execute(on_event?)` â†’ ExecutionResult (includes `total_cost`)

Mock mode: set `PLUGAH_MODE=mock` or pass `--mock`/`mock: true` to run deterministically without network/API keys.

### SerenPlanner architecture

- Default: Seren installs itself as the planner at import-time. You can disable it via `SEREN_PLANNER=off`.
- Mock: In `PLUGAH_MODE=mock`, Seren generates a deterministic OAG with budget-aware heuristics (no network calls).
- CrewAI path: In non-mock mode, Seren spins up a small Crew (e.g., an â€œOrg Architectâ€ agent) and instructs it to emit strict JSON describing:
  - `agents`: role hierarchy via `reports_to`
  - `tasks`: title/description/assignee/dependencies/DoD
  Seren parses the JSON and constructs a valid OAG (Agents, Tasks, Edges). If parsing fails or providers are unavailable, Seren falls back to heuristics.

### Provider configuration

Seren relies on the underlying CrewAI/LiteLLM provider configuration. Common environment variables:
- `OPENAI_API_KEY` (or other LiteLLM-compatible providers)
- Optional: model hints via CLI `--model` are forwarded to Plugah where possible

You can also disable Serenâ€™s injection with `SEREN_PLANNER=off` to use Plugahâ€™s stock planner.

## Testing ğŸ§ª

```bash
pytest -q
```

Tests run in mock mode and validate Discovery â†’ PRD â†’ OAG â†’ Execution, asserting a `total_cost` is returned.

Additional CLI smoke test validates artifact generation via `quickstart --mock`.

## Notes ğŸ§­

- The CLI accepts `--policy` (CONSERVATIVE|BALANCED|AGGRESSIVE) and `--model` as a hint to [Plugah](https://github.com/cheesejaguar/plugah).
- OAG and results are safely JSONâ€‘serialized even when returned as Pydantic models.
